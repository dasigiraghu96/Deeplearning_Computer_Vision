{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cat_dog.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1E9EWWj3x2rjEXey_NYKXXKPB6BVSnuHN",
      "authorship_tag": "ABX9TyOFwLQ5hlwzMk8MTktcnwcu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dasigiraghu96/Deeplearning_Computer_Vision/blob/main/cat_dog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJUjvIjLhhEm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa2d5bd3-763a-4969-afe7-697080a46c89"
      },
      "source": [
        "from google.colab import drive \r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xytxwJD8iCV"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img,img_to_array"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BgH0CE25Tq_",
        "outputId": "14cea2d5-611c-4b27-d597-32c81f259db2"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\r\n",
        "                                   shear_range = 0.2,\r\n",
        "                                   zoom_range = 0.2,\r\n",
        "                                   horizontal_flip = True)\r\n",
        "\r\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/cats_and_dogs_filtered/cats_and_dogs_filtered/train',\r\n",
        "                                                 target_size = (64, 64),\r\n",
        "                                                 batch_size = 32,\r\n",
        "                                                 class_mode = 'binary')\r\n",
        "\r\n",
        "# Preprocessing the Test set\r\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\r\n",
        "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/cats_and_dogs_filtered/cats_and_dogs_filtered/validation',\r\n",
        "                                            target_size = (64, 64),\r\n",
        "                                            batch_size = 32,\r\n",
        "                                            class_mode = 'binary')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_PoCGXXzT3W",
        "outputId": "c0aac985-53dc-432a-c77f-c8f99330c2ba"
      },
      "source": [
        "test_all = test_datagen.flow_from_directory('/content/drive/MyDrive/cats_and_dogs_filtered/cats_and_dogs_filtered/validation',\r\n",
        "                                            target_size = (64, 64),\r\n",
        "                                            batch_size = 1000,\r\n",
        "                                            class_mode = 'binary')\r\n",
        "x_test,y_test=test_all.next()\r\n",
        "print(x_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1000 images belonging to 2 classes.\n",
            "(1000, 64, 64, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ch8li1P1Gu1",
        "outputId": "78c9d467-ea2e-451f-c648-9afcc2be2fee"
      },
      "source": [
        "y_test[0]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHGTCNm_wlJ3"
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LS_abz9sx5Ug"
      },
      "source": [
        "cnn=tf.keras.models.Sequential()\r\n",
        "\r\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,padding='same',activation='relu',\r\n",
        "                               data_format=\"channels_last\",input_shape=(64,64,3)))\r\n",
        "\r\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2))\r\n",
        "\r\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,padding='same',activation='relu'))\r\n",
        "\r\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2))\r\n",
        "\r\n",
        "cnn.add(tf.keras.layers.Flatten())\r\n",
        "\r\n",
        "cnn.add(tf.keras.layers.Dense(128,activation='relu'))\r\n",
        "\r\n",
        "cnn.add(tf.keras.layers.Dense(84,activation='relu'))\r\n",
        "\r\n",
        "cnn.add(tf.keras.layers.Dense(1,activation='sigmoid'))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HsMdwbEyP6e",
        "outputId": "6d48e4a8-8363-48c3-b110-7848ab54d7f5"
      },
      "source": [
        "cnn.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 64, 64, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               1048704   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 84)                10836     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 85        \n",
            "=================================================================\n",
            "Total params: 1,069,769\n",
            "Trainable params: 1,069,769\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEeW2NW41OrO",
        "outputId": "65c728ac-eff3-4dbc-e39d-05ccc42e686a"
      },
      "source": [
        "\r\n",
        "# Part 3 - Training the CNN\r\n",
        "\r\n",
        "# Compiling the CNN\r\n",
        "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\r\n",
        "\r\n",
        "# Training the CNN on the Training set and evaluating it on the Test set\r\n",
        "cnn.fit(x = training_set, validation_data = test_set, epochs = 10)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "63/63 [==============================] - 1107s 17s/step - loss: 0.7003 - accuracy: 0.5267 - val_loss: 0.6900 - val_accuracy: 0.5100\n",
            "Epoch 2/10\n",
            "63/63 [==============================] - 12s 186ms/step - loss: 0.6933 - accuracy: 0.5133 - val_loss: 0.6965 - val_accuracy: 0.5080\n",
            "Epoch 3/10\n",
            "63/63 [==============================] - 12s 186ms/step - loss: 0.6814 - accuracy: 0.5715 - val_loss: 0.6496 - val_accuracy: 0.6030\n",
            "Epoch 4/10\n",
            "63/63 [==============================] - 12s 185ms/step - loss: 0.6351 - accuracy: 0.6617 - val_loss: 0.6421 - val_accuracy: 0.6350\n",
            "Epoch 5/10\n",
            "63/63 [==============================] - 12s 184ms/step - loss: 0.5957 - accuracy: 0.6948 - val_loss: 0.6030 - val_accuracy: 0.6700\n",
            "Epoch 6/10\n",
            "63/63 [==============================] - 11s 183ms/step - loss: 0.5914 - accuracy: 0.7108 - val_loss: 0.5883 - val_accuracy: 0.6980\n",
            "Epoch 7/10\n",
            "63/63 [==============================] - 12s 183ms/step - loss: 0.6066 - accuracy: 0.6853 - val_loss: 0.5756 - val_accuracy: 0.6920\n",
            "Epoch 8/10\n",
            "63/63 [==============================] - 11s 183ms/step - loss: 0.5301 - accuracy: 0.7473 - val_loss: 0.5632 - val_accuracy: 0.6990\n",
            "Epoch 9/10\n",
            "63/63 [==============================] - 11s 183ms/step - loss: 0.5030 - accuracy: 0.7665 - val_loss: 0.5805 - val_accuracy: 0.6990\n",
            "Epoch 10/10\n",
            "63/63 [==============================] - 12s 184ms/step - loss: 0.5165 - accuracy: 0.7451 - val_loss: 0.5601 - val_accuracy: 0.7070\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3d936f4790>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mx_eHgPI1x6f"
      },
      "source": [
        "from tensorflow.keras.models import load_model\r\n",
        "cnn.save('/content/drive/MyDrive/cats_and_dogs_filtered/model_cat_dog.h5')\r\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPXJPo9RXH1I"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsF3xDmY30iE",
        "outputId": "c0ff5aa0-fd04-4e75-9596-37a42375061b"
      },
      "source": [
        "from tensorflow.keras.models import load_model\r\n",
        "model=load_model('/content/drive/MyDrive/cats_and_dogs_filtered/model_cat_dog.h5')\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 64, 64, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               1048704   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 84)                10836     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 85        \n",
            "=================================================================\n",
            "Total params: 1,069,769\n",
            "Trainable params: 1,069,769\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JChWgUvPL22S"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z80dH_M_38tl",
        "outputId": "390f3a38-d53d-4f39-a9ba-b132cac8fa6f"
      },
      "source": [
        "import numpy as np\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img,img_to_array\r\n",
        "test_image=load_img('/content/drive/MyDrive/cats_and_dogs_filtered/cats_and_dogs_filtered/validation/cats/cat.2000.jpg',target_size=(64,64))\r\n",
        "test_image=img_to_array(test_image)\r\n",
        "test_image=test_image/255\r\n",
        "test_image=np.expand_dims(test_image,axis=0)\r\n",
        "result=model.predict(test_image)\r\n",
        "\r\n",
        "\r\n",
        "if result[0]<=0.5:\r\n",
        "    print(\"The image classified is cat\")\r\n",
        "else:\r\n",
        "    print(\"The image classified is dog\")\r\n",
        "\r\n",
        "print"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The image classified is cat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "JDpc4xhSMC3B",
        "outputId": "d8873cf0-93cf-4ea5-fcae-f03b14b28b32"
      },
      "source": [
        "test=load_img('/content/drive/MyDrive/cats_and_dogs_filtered/cats_and_dogs_filtered/validation/cats/cat.2000.jpg',target_size=(64,64))\r\n",
        "test"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F3D928F7690>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6FOi8TbMDra"
      },
      "source": [
        "##Create CNN model and keras hyperturning"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTeE27QHVgom",
        "outputId": "223503f0-929b-4803-ce31-d506bc8818e3"
      },
      "source": [
        "!pip install keras-tuner"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-tuner\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/ec/1ef246787174b1e2bb591c95f29d3c1310070cad877824f907faba3dade9/keras-tuner-1.0.2.tar.gz (62kB)\n",
            "\r\u001b[K     |█████▏                          | 10kB 22.6MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 20kB 29.6MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 30kB 21.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 40kB 24.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 51kB 23.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 61kB 17.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (20.9)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.19.5)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.8.9)\n",
            "Collecting terminaltables\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.22.2.post1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->keras-tuner) (1.0.1)\n",
            "Building wheels for collected packages: keras-tuner, terminaltables\n",
            "  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-tuner: filename=keras_tuner-1.0.2-cp37-none-any.whl size=78938 sha256=c721f7cf885f7747aa0855abcb28bca385f784c96c4998a95d7156b8d0dbee6c\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/a1/8a/7c3de0efb3707a1701b36ebbfdbc4e67aedf6d4943a1f463d6\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp37-none-any.whl size=15356 sha256=599fb4c030c4b75293e4d8e2f54d2e6d4cbb33a6fc3badce49dcf539f1e024d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n",
            "Successfully built keras-tuner terminaltables\n",
            "Installing collected packages: terminaltables, colorama, keras-tuner\n",
            "Successfully installed colorama-0.4.4 keras-tuner-1.0.2 terminaltables-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7IRmfayV5Kr"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "import numpy as np"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "a2q0QGn5WEkS",
        "outputId": "c5d5ce8a-9c2c-4a03-c7b7-1ff5c67c1001"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1T28hEJ_Zflp"
      },
      "source": [
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import layers\r\n",
        "def build_model(hp):\r\n",
        "  cnn=tf.keras.models.Sequential()\r\n",
        "  for i in range(hp.Int('num_layers', 2, 10)):\r\n",
        "    cnn.add(tf.keras.layers.Conv2D(filters=hp.Int('filters_conv'+str(i),min_value=32,max_value=128,step=16),\r\n",
        "                                 kernel_size=hp.Choice('kernel_conv'+str(i),values = [3,5,7]),\r\n",
        "                                 padding='same',\r\n",
        "                                 activation='relu',data_format=\"channels_last\",input_shape=(64,64,3)))\r\n",
        "\r\n",
        "  cnn.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2))\r\n",
        "\r\n",
        "  cnn.add(tf.keras.layers.Flatten())\r\n",
        "\r\n",
        "  cnn.add(tf.keras.layers.Dense(128,activation='relu'))\r\n",
        "\r\n",
        "  cnn.add(tf.keras.layers.Dense(84,activation='relu'))\r\n",
        "\r\n",
        "  cnn.add(tf.keras.layers.Dense(1,activation='sigmoid'))\r\n",
        "\r\n",
        "  cnn.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[0.1,1e-2, 1e-3])),\r\n",
        "              loss='binary_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "  return cnn"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6T3pWlHWJEL"
      },
      "source": [
        "from kerastuner import RandomSearch\r\n",
        "from kerastuner.engine.hyperparameters import HyperParameters"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QM52gmscQoR",
        "outputId": "4054c622-1852-40c3-f6f6-3668cccf40ea"
      },
      "source": [
        "tuner_search=RandomSearch(build_model,\r\n",
        "                          objective='val_accuracy',\r\n",
        "                          max_trials=5,directory='/content/drive/MyDrive/cats_and_dogs_filtered/output',\r\n",
        "                          project_name=\"dog_cat\")"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reloading Oracle from existing project /content/drive/MyDrive/cats_and_dogs_filtered/output/dog_cat/oracle.json\n",
            "INFO:tensorflow:Reloading Tuner from /content/drive/MyDrive/cats_and_dogs_filtered/output/dog_cat/tuner0.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hxyqvrfdQnZ",
        "outputId": "b5f5d3bb-64d5-4708-ac9f-19ff3af89548"
      },
      "source": [
        "tuner_search.search_space_summary()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Search space summary\n",
            "Default search space size: 16\n",
            "num_layers (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 10, 'step': 1, 'sampling': None}\n",
            "filters_conv0 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 16, 'sampling': None}\n",
            "kernel_conv0 (Choice)\n",
            "{'default': 3, 'conditions': [], 'values': [3, 5, 7], 'ordered': True}\n",
            "filters_conv1 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 16, 'sampling': None}\n",
            "kernel_conv1 (Choice)\n",
            "{'default': 3, 'conditions': [], 'values': [3, 5, 7], 'ordered': True}\n",
            "learning_rate (Choice)\n",
            "{'default': 0.1, 'conditions': [], 'values': [0.1, 0.01, 0.001], 'ordered': True}\n",
            "filters_conv2 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 16, 'sampling': None}\n",
            "kernel_conv2 (Choice)\n",
            "{'default': 3, 'conditions': [], 'values': [3, 5, 7], 'ordered': True}\n",
            "filters_conv3 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 16, 'sampling': None}\n",
            "kernel_conv3 (Choice)\n",
            "{'default': 3, 'conditions': [], 'values': [3, 5, 7], 'ordered': True}\n",
            "filters_conv4 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 16, 'sampling': None}\n",
            "kernel_conv4 (Choice)\n",
            "{'default': 3, 'conditions': [], 'values': [3, 5, 7], 'ordered': True}\n",
            "filters_conv5 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 16, 'sampling': None}\n",
            "kernel_conv5 (Choice)\n",
            "{'default': 3, 'conditions': [], 'values': [3, 5, 7], 'ordered': True}\n",
            "filters_conv6 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 16, 'sampling': None}\n",
            "kernel_conv6 (Choice)\n",
            "{'default': 3, 'conditions': [], 'values': [3, 5, 7], 'ordered': True}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kc-rKXSY0rrG",
        "outputId": "8bc00d2b-11a1-450b-dd00-770e1f7a827a"
      },
      "source": [
        "import numpy as np\r\n",
        "train_generator=train_datagen.flow_from_directory('/content/drive/MyDrive/cats_and_dogs_filtered/cats_and_dogs_filtered/train',\r\n",
        "                                                 target_size = (64, 64),\r\n",
        "                                                 batch_size = 32,\r\n",
        "                                                 class_mode = 'binary')\r\n",
        "x_train=np.concatenate([train_generator.next()[0] for i in range(train_generator.__len__())])\r\n",
        "y_train=np.concatenate([train_generator.next()[1] for i in range(train_generator.__len__())])\r\n",
        "print(x_train.shape)\r\n",
        "print(y_train.shape)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "(2000, 64, 64, 3)\n",
            "(2000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Hiiy0m-11o1",
        "outputId": "e8e17f89-2f91-484e-f8f1-4706a9de897a"
      },
      "source": [
        "test_generator=test_datagen.flow_from_directory('/content/drive/MyDrive/cats_and_dogs_filtered/cats_and_dogs_filtered/validation',\r\n",
        "                                            target_size = (64, 64),\r\n",
        "                                            batch_size = 32,\r\n",
        "                                            class_mode = 'binary')\r\n",
        "x_test=np.concatenate([test_generator.next()[0] for i in range(test_generator.__len__())])\r\n",
        "y_test=np.concatenate([test_generator.next()[1] for i in range(test_generator.__len__())])\r\n",
        "print(x_test.shape)\r\n",
        "print(y_test.shape)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1000 images belonging to 2 classes.\n",
            "(1000, 64, 64, 3)\n",
            "(1000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIKm1XxUfcJr",
        "outputId": "d1fa9fcc-5fd1-4385-c7e2-1ef0cdd8f861"
      },
      "source": [
        "tuner_search.search(x_train,y_train,epochs=3,validation_split=0.1)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Oracle triggered exit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02uTzwxOfn1B"
      },
      "source": [
        "model=tuner_search.get_best_models(num_models=1)[0]"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anSERDFM3fst",
        "outputId": "fe35cc1f-0f03-43fa-acf2-27fcd2ea1e7d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 64, 64, 96)        2688      \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 64, 64, 128)       110720    \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 64, 64, 32)        36896     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 64, 64, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               4194432   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 84)                10836     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 85        \n",
            "=================================================================\n",
            "Total params: 4,364,905\n",
            "Trainable params: 4,364,905\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lY0Lm8q93iDN",
        "outputId": "c42030fb-d45f-4885-9da6-6f51186b558d"
      },
      "source": [
        "model.fit(x_train,y_train,epochs=10, validation_split=0.1, initial_epoch=3)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/10\n",
            "57/57 [==============================] - 2s 30ms/step - loss: nan - accuracy: 0.4983 - val_loss: nan - val_accuracy: 0.5150\n",
            "Epoch 5/10\n",
            "57/57 [==============================] - 2s 28ms/step - loss: nan - accuracy: 0.4983 - val_loss: nan - val_accuracy: 0.5150\n",
            "Epoch 6/10\n",
            "57/57 [==============================] - 2s 28ms/step - loss: nan - accuracy: 0.4983 - val_loss: nan - val_accuracy: 0.5150\n",
            "Epoch 7/10\n",
            "57/57 [==============================] - 2s 28ms/step - loss: nan - accuracy: 0.4983 - val_loss: nan - val_accuracy: 0.5150\n",
            "Epoch 8/10\n",
            "57/57 [==============================] - 2s 28ms/step - loss: nan - accuracy: 0.4983 - val_loss: nan - val_accuracy: 0.5150\n",
            "Epoch 9/10\n",
            "57/57 [==============================] - 2s 28ms/step - loss: nan - accuracy: 0.4983 - val_loss: nan - val_accuracy: 0.5150\n",
            "Epoch 10/10\n",
            "57/57 [==============================] - 2s 28ms/step - loss: nan - accuracy: 0.4983 - val_loss: nan - val_accuracy: 0.5150\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f01803e6310>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    }
  ]
}